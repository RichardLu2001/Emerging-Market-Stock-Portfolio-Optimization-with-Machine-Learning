{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea35274e-713e-4dc1-95f2-2bcd22e2c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28604\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14f0957-868a-47d6-8c4c-15e953344152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./MomentumFeature.pkl', 'rb') as f:\n",
    "    tech_data = pickle.load(f)\n",
    "with open('./FundamentalData.pkl', 'rb') as f:\n",
    "    fun_data = pickle.load(f)\n",
    "    \n",
    "for stock in tech_data:\n",
    "    tech_data[stock].index = pd.to_datetime(tech_data[stock].index, errors='coerce')\n",
    "\n",
    "for stock in fun_data:\n",
    "    fun_data[stock].index = pd.to_datetime(fun_data[stock].index, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a2d4c8-9211-451c-941e-d0dc94b30543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stock: 000001\n",
      "Train Stock: 000002\n",
      "Train Stock: 000063\n",
      "Train Stock: 000100\n",
      "Train Stock: 000157\n",
      "Train Stock: 000166\n",
      "Train Stock: 000301\n",
      "Train Stock: 000333\n",
      "Train Stock: 000338\n",
      "Train Stock: 000408\n",
      "Train Stock: 000425\n",
      "Train Stock: 000538\n",
      "Train Stock: 000568\n",
      "Train Stock: 000596\n",
      "Train Stock: 000617\n",
      "Train Stock: 000625\n",
      "Train Stock: 000651\n",
      "Train Stock: 000661\n",
      "Train Stock: 000708\n",
      "Train Stock: 000725\n",
      "Train Stock: 000733\n",
      "Train Stock: 000768\n",
      "Train Stock: 000776\n",
      "Train Stock: 000786\n",
      "Train Stock: 000792\n",
      "Train Stock: 000800\n",
      "Train Stock: 000807\n",
      "Train Stock: 000858\n",
      "Train Stock: 000876\n",
      "Train Stock: 000895\n",
      "Train Stock: 000938\n",
      "Train Stock: 000963\n",
      "Train Stock: 000977\n",
      "Train Stock: 000983\n",
      "Train Stock: 000999\n",
      "Stock Delete: 001289\n",
      "Stock Delete: 001965\n",
      "Train Stock: 001979\n",
      "Train Stock: 002001\n",
      "Train Stock: 002007\n",
      "Train Stock: 002027\n",
      "Train Stock: 002049\n",
      "Train Stock: 002050\n",
      "Train Stock: 002074\n",
      "Train Stock: 002129\n",
      "Train Stock: 002142\n",
      "Train Stock: 002179\n",
      "Train Stock: 002180\n",
      "Train Stock: 002230\n",
      "Train Stock: 002236\n",
      "Train Stock: 002241\n",
      "Train Stock: 002252\n",
      "Train Stock: 002271\n",
      "Train Stock: 002304\n",
      "Train Stock: 002311\n",
      "Train Stock: 002352\n",
      "Train Stock: 002371\n",
      "Train Stock: 002410\n",
      "Train Stock: 002415\n",
      "Train Stock: 002459\n",
      "Train Stock: 002460\n",
      "Train Stock: 002466\n",
      "Train Stock: 002475\n",
      "Train Stock: 002493\n",
      "Train Stock: 002555\n",
      "Train Stock: 002594\n",
      "Train Stock: 002601\n",
      "Train Stock: 002603\n",
      "Train Stock: 002648\n",
      "Train Stock: 002709\n",
      "Train Stock: 002714\n",
      "Train Stock: 002736\n",
      "Train Stock: 002812\n",
      "Stock Delete: 002821\n",
      "Stock Delete: 002841\n",
      "Stock Delete: 002916\n",
      "Stock Delete: 002920\n",
      "Stock Delete: 002938\n",
      "Stock Delete: 003816\n",
      "Train Stock: 300014\n",
      "Train Stock: 300015\n",
      "Train Stock: 300033\n",
      "Train Stock: 300059\n",
      "Train Stock: 300122\n",
      "Train Stock: 300124\n",
      "Train Stock: 300142\n",
      "Train Stock: 300223\n",
      "Train Stock: 300274\n",
      "Train Stock: 300308\n",
      "Train Stock: 300316\n",
      "Train Stock: 300347\n",
      "Train Stock: 300408\n",
      "Train Stock: 300413\n",
      "Train Stock: 300418\n",
      "Train Stock: 300433\n",
      "Train Stock: 300442\n",
      "Train Stock: 300450\n",
      "Stock Delete: 300454\n",
      "Train Stock: 300496\n",
      "Train Stock: 300498\n",
      "Stock Delete: 300628\n",
      "Stock Delete: 300661\n",
      "Stock Delete: 300750\n",
      "Stock Delete: 300751\n",
      "Stock Delete: 300759\n",
      "Stock Delete: 300760\n",
      "Stock Delete: 300782\n",
      "Stock Delete: 300832\n",
      "Stock Delete: 300896\n",
      "Stock Delete: 300919\n",
      "Stock Delete: 300957\n",
      "Stock Delete: 300979\n",
      "Stock Delete: 300999\n",
      "Stock Delete: 301269\n",
      "Train Stock: 600000\n",
      "Train Stock: 600009\n",
      "Train Stock: 600010\n",
      "Train Stock: 600011\n",
      "Train Stock: 600015\n",
      "Train Stock: 600016\n",
      "Train Stock: 600018\n",
      "Train Stock: 600019\n",
      "Train Stock: 600023\n",
      "Stock Delete: 600025\n",
      "Train Stock: 600026\n",
      "Train Stock: 600027\n",
      "Train Stock: 600028\n",
      "Train Stock: 600029\n",
      "Train Stock: 600030\n",
      "Train Stock: 600031\n",
      "Train Stock: 600036\n",
      "Train Stock: 600039\n",
      "Train Stock: 600048\n",
      "Train Stock: 600050\n",
      "Train Stock: 600061\n",
      "Train Stock: 600085\n",
      "Train Stock: 600089\n",
      "Train Stock: 600104\n",
      "Train Stock: 600111\n",
      "Train Stock: 600115\n",
      "Train Stock: 600132\n",
      "Train Stock: 600150\n",
      "Train Stock: 600161\n",
      "Train Stock: 600176\n",
      "Train Stock: 600183\n",
      "Train Stock: 600188\n",
      "Train Stock: 600196\n",
      "Train Stock: 600219\n",
      "Train Stock: 600233\n",
      "Train Stock: 600276\n",
      "Train Stock: 600309\n",
      "Train Stock: 600332\n",
      "Train Stock: 600346\n",
      "Train Stock: 600362\n",
      "Train Stock: 600372\n",
      "Train Stock: 600406\n",
      "Train Stock: 600415\n",
      "Train Stock: 600426\n",
      "Train Stock: 600436\n",
      "Train Stock: 600438\n",
      "Train Stock: 600460\n",
      "Train Stock: 600489\n",
      "Train Stock: 600515\n",
      "Train Stock: 600519\n",
      "Train Stock: 600547\n",
      "Train Stock: 600570\n",
      "Train Stock: 600584\n",
      "Train Stock: 600585\n",
      "Train Stock: 600588\n",
      "Train Stock: 600600\n",
      "Train Stock: 600660\n",
      "Train Stock: 600674\n",
      "Train Stock: 600690\n",
      "Train Stock: 600732\n",
      "Train Stock: 600741\n",
      "Train Stock: 600745\n",
      "Train Stock: 600760\n",
      "Train Stock: 600795\n",
      "Train Stock: 600803\n",
      "Train Stock: 600809\n",
      "Train Stock: 600837\n",
      "Train Stock: 600845\n",
      "Train Stock: 600875\n",
      "Train Stock: 600886\n",
      "Train Stock: 600887\n",
      "Train Stock: 600893\n",
      "Train Stock: 600900\n",
      "Stock Delete: 600905\n",
      "Stock Delete: 600918\n",
      "Train Stock: 600919\n",
      "Stock Delete: 600926\n",
      "Stock Delete: 600938\n",
      "Stock Delete: 600941\n",
      "Train Stock: 600958\n",
      "Stock Delete: 600989\n",
      "Train Stock: 600999\n",
      "Train Stock: 601006\n",
      "Train Stock: 601009\n",
      "Stock Delete: 601012\n",
      "Train Stock: 601021\n",
      "Stock Delete: 601059\n",
      "Stock Delete: 601066\n",
      "Train Stock: 601088\n",
      "Train Stock: 601100\n",
      "Train Stock: 601111\n",
      "Train Stock: 601117\n",
      "Stock Delete: 601138\n",
      "Train Stock: 601166\n",
      "Train Stock: 601169\n",
      "Train Stock: 601186\n",
      "Train Stock: 601211\n",
      "Train Stock: 601225\n",
      "Stock Delete: 601229\n",
      "Stock Delete: 601236\n",
      "Train Stock: 601238\n",
      "Train Stock: 601288\n",
      "Train Stock: 601318\n",
      "Stock Delete: 601319\n",
      "Train Stock: 601328\n",
      "Train Stock: 601336\n",
      "Train Stock: 601360\n",
      "Train Stock: 601377\n",
      "Train Stock: 601390\n",
      "Train Stock: 601398\n",
      "Train Stock: 601600\n",
      "Train Stock: 601601\n",
      "Train Stock: 601607\n",
      "Train Stock: 601618\n",
      "Train Stock: 601628\n",
      "Train Stock: 601633\n",
      "Stock Delete: 601658\n",
      "Train Stock: 601668\n",
      "Train Stock: 601669\n",
      "Train Stock: 601688\n",
      "Train Stock: 601689\n",
      "Stock Delete: 601698\n",
      "Train Stock: 601699\n",
      "Stock Delete: 601728\n",
      "Train Stock: 601766\n",
      "Train Stock: 601788\n",
      "Train Stock: 601799\n",
      "Train Stock: 601800\n",
      "Train Stock: 601808\n",
      "Stock Delete: 601816\n",
      "Train Stock: 601818\n",
      "Stock Delete: 601838\n",
      "Stock Delete: 601857\n",
      "Stock Delete: 601865\n",
      "Stock Delete: 601868\n",
      "Train Stock: 601872\n",
      "Train Stock: 601877\n",
      "Stock Delete: 601878\n",
      "Stock Delete: 601881\n",
      "Train Stock: 601888\n",
      "Train Stock: 601898\n",
      "Train Stock: 601899\n",
      "Train Stock: 601901\n",
      "Stock Delete: 601916\n",
      "Train Stock: 601919\n",
      "Train Stock: 601939\n",
      "Train Stock: 601985\n",
      "Train Stock: 601988\n",
      "Train Stock: 601989\n",
      "Stock Delete: 601995\n",
      "Train Stock: 601998\n",
      "Train Stock: 603019\n",
      "Stock Delete: 603195\n",
      "Stock Delete: 603259\n",
      "Stock Delete: 603260\n",
      "Stock Delete: 603288\n",
      "Stock Delete: 603296\n",
      "Train Stock: 603369\n",
      "Stock Delete: 603392\n",
      "Stock Delete: 603501\n",
      "Stock Delete: 603659\n",
      "Train Stock: 603799\n",
      "Train Stock: 603806\n",
      "Stock Delete: 603833\n",
      "Train Stock: 603899\n",
      "Train Stock: 603986\n",
      "Train Stock: 603993\n",
      "Stock Delete: 605117\n",
      "Stock Delete: 605499\n",
      "Stock Delete: 688008\n",
      "Stock Delete: 688009\n",
      "Stock Delete: 688012\n",
      "Stock Delete: 688036\n",
      "Stock Delete: 688041\n",
      "Stock Delete: 688082\n",
      "Stock Delete: 688111\n",
      "Stock Delete: 688126\n",
      "Stock Delete: 688187\n",
      "Stock Delete: 688223\n",
      "Stock Delete: 688256\n",
      "Stock Delete: 688271\n",
      "Stock Delete: 688303\n",
      "Stock Delete: 688363\n",
      "Stock Delete: 688396\n",
      "Stock Delete: 688599\n",
      "Stock Delete: 688981\n"
     ]
    }
   ],
   "source": [
    "cutoff_date = pd.to_datetime(\"2020-01-01\")\n",
    "stocks_to_remove = []\n",
    "model_dict = {}\n",
    "\n",
    "def scale_non_nan(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = X.copy()\n",
    "    for col in X.columns:\n",
    "        # Mask to get non-NaN values\n",
    "        mask = X[col].notna()\n",
    "        \n",
    "        # Only apply scaling if there are more than 3 non-NaN values in the column\n",
    "        if mask.sum() > 3:  # Proceed if there are more than 3 non-NaN values\n",
    "            # Fit-transform only on non-NaN values and reassign to the DataFrame\n",
    "            X_scaled.loc[mask, col] = scaler.fit_transform(X[[col]].loc[mask].values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled\n",
    "\n",
    "# Wrapper function to use in the pipeline\n",
    "def non_nan_scaler(X):\n",
    "    return scale_non_nan(X)\n",
    "\n",
    "for stock, data in list(fun_data.items()):\n",
    "    data_before_2020 = data[data.index < cutoff_date].copy()\n",
    "    data_before_2020.dropna(subset=['ret'], inplace=True)\n",
    "    data_before_2020['ret'] = data_before_2020['ret'].shift(-1)\n",
    "    data_before_2020.dropna(subset=['ret'], inplace=True)\n",
    "\n",
    "    first_5_cols = data_before_2020.columns[:5]\n",
    "    data_before_2020 = data_before_2020[~(data_before_2020[first_5_cols].isna().sum(axis=1) >= 3)]\n",
    "    \n",
    "    if len(data_before_2020) < 12:\n",
    "        print(\"Stock Delete: \" + str(stock))\n",
    "        stocks_to_remove.append(stock)\n",
    "        continue\n",
    "    \n",
    "    print(\"Train Stock: \" + str(stock))\n",
    "    y_train = data_before_2020['ret']\n",
    "    X_train = data_before_2020.drop(columns=['ret', 'Adj_close_price']).loc[y_train.index]\n",
    "    \n",
    "    # Define pipeline with custom scaler\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', FunctionTransformer(non_nan_scaler)),\n",
    "        ('xgb', XGBRegressor(objective='reg:squarederror'))\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "    avg_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Fit the pipeline on the entire training set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Store the pipeline and CV score\n",
    "    model_dict[stock] = {\n",
    "        'pipeline': pipeline,\n",
    "        'cv_score': avg_cv_score\n",
    "    }\n",
    "\n",
    "# Remove stocks with insufficient data\n",
    "for stock in stocks_to_remove:\n",
    "    del fun_data[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a901371-9ff7-4d27-87b6-6f7e1c45be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_dict.pkl', 'rb') as file:\n",
    "    loaded_model_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745d2b03-845b-4f04-ab8c-c99da01a41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FunDataCleaned.pkl', 'wb') as file:\n",
    "    pickle.dump(fun_data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
